{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change utility1 by the corresponding number, get back utility 3  done\n",
    "#change prompt done\n",
    "#change pickle filename  done\n",
    "#change plot name   done\n",
    "#change objective name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NTeLbyDoMi0-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Suppress potential optimization warnings for cleaner notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 07:50:27.184951: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-29 07:50:27.223956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 07:50:27.953754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-29 07:50:28.392870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-29 07:50:28.393531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import DTLZ2_model\n",
    "import fischer_model\n",
    "from botorch.test_functions.multi_objective import DTLZ2\n",
    "from DTLZ2_model import neg_l1_dist\n",
    "from DTLZ2_model import predict_DTLZ2_model\n",
    "from fischer_model import predict_fischer_model\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll \n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood \n",
    "from botorch.models.transforms.input import Normalize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Your chosen seed\n",
    "your_seed = 42\n",
    "\n",
    "# Set seed for Python's RNG\n",
    "random.seed(your_seed)\n",
    "\n",
    "# Set seed for NumPy RNG\n",
    "np.random.seed(your_seed)\n",
    "\n",
    "# Set seed for PyTorch RNGs\n",
    "torch.manual_seed(your_seed)\n",
    "\n",
    "# Ensure reproducibility for PyTorch operations (might reduce performance)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# If using CUDA (PyTorch)\n",
    "torch.cuda.manual_seed(your_seed)\n",
    "torch.cuda.manual_seed_all(your_seed)  # For multi-GPU setups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6455, 0.0591, 0.1161, 0.5071]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fischer_model(torch.tensor([[0.5, 0.5, 0.5, 0.5]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('9ylnov4iFULBLovujZIJLq6x8pkq4NkyNCw0oePR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Mvj4PbSpNSjG"
   },
   "outputs": [],
   "source": [
    "# data generating helper functions\n",
    "#function that defines the comparisons\n",
    "def utility(X):\n",
    "    y=predict_fischer_model(X)\n",
    "    #weighted_y = y * torch.sqrt(torch.arange(y.size(-1), dtype=torch.float) + 1)\n",
    "    #y = torch.sum(weighted_y, dim=-1)\n",
    "    return y\n",
    "\n",
    "def utility1(X): #The four outputs are equally important, and we want to maximize all of them.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = torch.sum(y, dim=-1)\n",
    "    return y\n",
    "\n",
    "def utility2(X): #We only want to maximize the CO conversion.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = y[:,0]\n",
    "    return y\n",
    "\n",
    "def utility3(X): # The light olefins is considered as a negative output and we want to minimize it while maximizing the other three objectives.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = y[:,0]+y[:,1]+y[:,2]-y[:,3]\n",
    "    return y\n",
    "    \n",
    "def ini(n,dim):\n",
    "    X = torch.rand(n, dim, dtype=torch.float64)\n",
    "    return X\n",
    "def generate_data(X, dim=4):\n",
    "    \"\"\"Generate data X and y\"\"\"\n",
    "    # X is randomly sampled from dim-dimentional unit cube\n",
    "    # we recommend using double as opposed to float tensor here for\n",
    "    # better numerical stability\n",
    "    #X=ini(n,dim)\n",
    "    x_2=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    y = utility(x_2)\n",
    "    return y\n",
    "\n",
    "def generate_data_u1(X, dim=4):\n",
    "    \"\"\"Generate data X and y\"\"\"\n",
    "    # X is randomly sampled from dim-dimentional unit cube\n",
    "    # we recommend using double as opposed to float tensor here for\n",
    "    # better numerical stability\n",
    "    #X=ini(n,dim)\n",
    "    x_2=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    y = utility1(x_2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparisons(y, n_comp, noise=0.1, replace=False):\n",
    "    \"\"\"Create pairwise comparisons with noise\"\"\"\n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[\n",
    "        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n",
    "    ]\n",
    "    # add gaussian noise to the latent y values\n",
    "    c0 = y[comp_pairs[:, 0]] + np.random.standard_normal(len(comp_pairs)) * noise\n",
    "    c1 = y[comp_pairs[:, 1]] + np.random.standard_normal(len(comp_pairs)) * noise\n",
    "    reverse_comp = (c0 < c1).numpy()\n",
    "    comp_pairs[reverse_comp, :] = np.flip(comp_pairs[reverse_comp, :], 1)\n",
    "    comp_pairs = torch.tensor(comp_pairs).long()\n",
    "\n",
    "    return comp_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im not sure if this is is the correct function, i'm a bit eepy\n",
    "#remember to reduce the number of comparisons n_comp,\n",
    "def generate_comparisons_llm(y, n_comp, replace=False):\n",
    "    \"\"\"Create pairwise comparisons with noise\"\"\"\n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[\n",
    "        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n",
    "    ]\n",
    "    #parsing the tensor to get the strings for the LLM\n",
    "    new_pairs=[]\n",
    "    for opto in comp_pairs:\n",
    "        firstoption=opto[0]\n",
    "        secondoption=opto[1]\n",
    "        numfirst=(y[firstoption,:])\n",
    "        firstoutput1=f\"{numfirst[0].cpu().numpy():.1f}\"\n",
    "        firstoutput2=f\"{numfirst[1].cpu().numpy():.1f}\"\n",
    "        firstoutput3=f\"{numfirst[2].cpu().numpy():.1f}\"\n",
    "        firstoutput4=f\"{numfirst[3].cpu().numpy():.1f}\"\n",
    "        numsecond=(y[secondoption,:])\n",
    "        secondoutput1=f\"{numsecond[0].cpu().numpy():.1f}\"\n",
    "        secondoutput2=f\"{numsecond[1].cpu().numpy():.1f}\"\n",
    "        secondoutput3=f\"{numsecond[2].cpu().numpy():.1f}\"\n",
    "        secondoutput4=f\"{numsecond[3].cpu().numpy():.1f}\"\n",
    "        #only two character are changed in the maximize word, 'ax' to 'in' giving minimize\n",
    "        mess=\"Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to minimize all of them. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane production, \"+firstoutput3+\" paraffins, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane production, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "        print(mess)\n",
    "        response = co.chat(message=mess,\n",
    "        #perform web search before answering the question. You can also use your own custom connector.\n",
    "                          #connectors=[{\"id\": \"web-search\"}]\n",
    "        )\n",
    "        print(response.text)\n",
    "        opllm=response.text\n",
    "        \n",
    "        if \"Option A\" in opllm:\n",
    "            new_pairs.append(opto.tolist())\n",
    "        else:\n",
    "            new_pairs.append(list(reversed(opto)))\n",
    "        #api restrictions 20 API calls/minutes\n",
    "        time.sleep(6)\n",
    "    \n",
    "    return torch.tensor(new_pairs)\n",
    "\n",
    "#\"Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane production, \"+firstoutput3+\" paraffins, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane production, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "#\"Suppose you're managing a Fischer-Tropsch synthesis process. The light olefins are considered as a negative output and we want to minimize them, while maximizing the other three outputs. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane, \"+firstoutput3+\" paraffin, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "#\"Suppose you're managing a Fischer-Tropsch synthesis process. We only want to maximize the CO conversion. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane, \"+firstoutput3+\" paraffin, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5F2xn-8N-g9"
   },
   "source": [
    "#parameters\n",
    "torch.manual_seed(123)\n",
    "#number for initial data\n",
    "n = 5 if not SMOKE_TEST else 5\n",
    "#number for initial comparisons\n",
    "m = 10 if not SMOKE_TEST else 10\n",
    "dim = 4\n",
    "noise = 0.1\n",
    "\n",
    "#generate data, initial data\n",
    "train_X, train_y = generate_data(n, dim=dim)\n",
    "#generating comparison based on the utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_comp_llm = generate_comparisons_llm(train_y, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_comp_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMuLBRO-NVj3"
   },
   "source": [
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
    "from botorch.models.transforms.input import Normalize\n",
    "\n",
    "#fitting the first pairwise GP\n",
    "model = PairwiseGP(\n",
    "    train_X,\n",
    "    train_comp_llm,\n",
    "    input_transform=Normalize(d=train_X.shape[-1]),\n",
    ")\n",
    "mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n",
    "mll = fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdxhkF6yNZKp",
    "outputId": "0e3b833e-7a46-4413-f148-7e3fab6d8433"
   },
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "\n",
    "# Kendall-Tau rank correlation\n",
    "def eval_kt_cor(model, test_X, test_y):\n",
    "    pred_y = model.posterior(test_X).mean.squeeze().detach().numpy()\n",
    "    return kendalltau(pred_y, test_y).correlation\n",
    "\n",
    "\n",
    "n_kendall = 10 if not SMOKE_TEST else 10\n",
    "\n",
    "test_X, test_y = generate_data(n_kendall, dim=dim)\n",
    "kt_correlation = eval_kt_cor(model, test_X, test_y[:,3])\n",
    "\n",
    "print(f\"Test Kendall-Tau rank correlation: {kt_correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qEoN28RSNk2N"
   },
   "outputs": [],
   "source": [
    "from botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#wrapper for the model\n",
    "def init_and_fit_model(X, comp):\n",
    "    \"\"\"Model fitting helper function\"\"\"\n",
    "    model = PairwiseGP(\n",
    "        X,\n",
    "        comp,\n",
    "        input_transform=Normalize(d=X.shape[-1]),\n",
    "    )\n",
    "    mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    return mll, model\n",
    "\n",
    "#wrapper for making new data, what does it mean? return comps\n",
    "\n",
    "def make_new_data(X, next_X, comps, q_comp):\n",
    "    \"\"\"Given X and next_X,\n",
    "    generate q_comp new comparisons between next_X\n",
    "    and return the concatenated X and comparisons\n",
    "    \"\"\"\n",
    "    # next_X is float by default; cast it to the dtype of X (i.e., double)\n",
    "    next_X = next_X.to(X)\n",
    "    x_2=tf.convert_to_tensor(next_X, dtype=tf.float32)\n",
    "    next_y = utility(x_2)\n",
    "    next_comps = generate_comparisons_llm(next_y, n_comp=q_comp)\n",
    "    comps = torch.cat([comps, next_comps + X.shape[-2]])\n",
    "    X = torch.cat([X, next_X])\n",
    "    return X, comps\n",
    "\n",
    "def make_new_data_u1(X, next_X, comps, q_comp):\n",
    "    \"\"\"Given X and next_X,\n",
    "    generate q_comp new comparisons between next_X\n",
    "    and return the concatenated X and comparisons\n",
    "    \"\"\"\n",
    "    # next_X is float by default; cast it to the dtype of X (i.e., double)\n",
    "    next_X = next_X.to(X)\n",
    "    x_2=tf.convert_to_tensor(next_X, dtype=tf.float32)\n",
    "    next_y = utility1(x_2)\n",
    "    next_comps = generate_comparisons(next_y, n_comp=q_comp)\n",
    "    comps = torch.cat([comps, next_comps + X.shape[-2]])\n",
    "    X = torch.cat([X, next_X])\n",
    "    return X, comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pTEh0DMNv1w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Option B: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.5 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.7 CO conversion, 0.1 methane production, 0.2 paraffins, 0.4 light olefins. Option B: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Option B: regime of 0.5 CO conversion, 0.0 methane production, 0.1 paraffins, 0.6 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.7 CO conversion, 0.1 methane production, 0.2 paraffins, 0.4 light olefins. Option B: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.5 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.7 CO conversion, 0.1 methane production, 0.2 paraffins, 0.4 light olefins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.5 CO conversion, 0.0 methane production, 0.1 paraffins, 0.6 light olefins. Option B: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.5 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n"
     ]
    }
   ],
   "source": [
    "#two algorithms to compare\n",
    "algos = [\"EUBO\",\"EUBO-LLM\", \"rand\"]\n",
    "#number of repetitions of the BO cycle\n",
    "NUM_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "#number of cycles\n",
    "NUM_BATCHES = 20 if not SMOKE_TEST else 2\n",
    "\n",
    "#dimension number= 4 inputs\n",
    "dim = 4\n",
    "#sampler options\n",
    "NUM_RESTARTS = 3\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 8\n",
    "#\n",
    "q_eubo = 2  # number of points per query\n",
    "q_data=5\n",
    "q_comp = 10  # number of comparisons per query\n",
    "q_comp_2=1\n",
    "\n",
    "# initial evals\n",
    "best_vals = {}  # best observed values\n",
    "for algo in algos:\n",
    "    best_vals[algo] = []\n",
    "\n",
    "# average over multiple trials\n",
    "for i in range(NUM_TRIALS):\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    data = {}\n",
    "    models = {}\n",
    "\n",
    "     # X are within the unit cube\n",
    "    bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "\n",
    "    # Create initial data\n",
    "    init_X=ini(q_data,dim)\n",
    "    for algo in algos:\n",
    "        if algo == \"EUBO-LLM\":\n",
    "            init_y = generate_data(init_X, dim=dim)\n",
    "            comparisons = generate_comparisons_llm(init_y, q_comp)\n",
    "        if algo == \"EUBO\":\n",
    "            init_y = generate_data_u1(init_X, dim=dim)\n",
    "            comparisons = generate_comparisons(init_y, q_comp)\n",
    "        if algo == \"rand\":\n",
    "            init_y = generate_data_u1(init_X, dim=dim)\n",
    "            comparisons = generate_comparisons(init_y, q_comp)\n",
    "   \n",
    "        best_vals[algo].append([])\n",
    "        data[algo] = (init_X, comparisons)\n",
    "        _, models[algo] = init_and_fit_model(init_X, comparisons)\n",
    "\n",
    "        best_next_y = utility1(init_X).max().item()\n",
    "        best_vals[algo][-1].append(best_next_y)\n",
    "\n",
    "    # we make additional NUM_BATCHES comparison queries after the initial observation\n",
    "    for j in range(1, NUM_BATCHES + 1):\n",
    "        print(j)\n",
    "        for algo in algos:\n",
    "            model = models[algo]\n",
    "            if algo == \"EUBO-LLM\":\n",
    "                # create the acquisition function object\n",
    "                acq_func = AnalyticExpectedUtilityOfBestOption(pref_model=model)\n",
    "                # optimize and get new observation\n",
    "                next_X, acq_val = optimize_acqf(\n",
    "                    acq_function=acq_func,\n",
    "                    bounds=bounds,\n",
    "                    q=q_eubo,\n",
    "                    num_restarts=NUM_RESTARTS,\n",
    "                    raw_samples=RAW_SAMPLES,\n",
    "                )\n",
    "                print(next_X)\n",
    "                # update data\n",
    "                X, comps = data[algo]\n",
    "                X, comps = make_new_data(X, next_X, comps, q_comp_2)\n",
    "                data[algo] = (X, comps)\n",
    "    \n",
    "                # refit models\n",
    "                _, models[algo] = init_and_fit_model(X, comps)\n",
    "    \n",
    "                # record the best observed values so far\n",
    "                max_val = utility1(X).max().item()\n",
    "                best_vals[algo][-1].append(max_val)\n",
    "            elif algo == \"EUBO\":\n",
    "                 #create the acquisition function object\n",
    "                acq_func = AnalyticExpectedUtilityOfBestOption(pref_model=model)\n",
    "                # optimize and get new observation\n",
    "                next_X, acq_val = optimize_acqf(\n",
    "                    acq_function=acq_func,\n",
    "                    bounds=bounds,\n",
    "                    q=q_eubo,\n",
    "                    num_restarts=NUM_RESTARTS,\n",
    "                    raw_samples=RAW_SAMPLES,\n",
    "                )\n",
    "                print(next_X)\n",
    "                # update data\n",
    "                X, comps = data[algo]\n",
    "                X, comps = make_new_data_u1(X, next_X, comps, q_comp_2)\n",
    "                data[algo] = (X, comps)\n",
    "    \n",
    "                # refit models\n",
    "                _, models[algo] = init_and_fit_model(X, comps)\n",
    "    \n",
    "                # record the best observed values so far\n",
    "                max_val = utility1(X).max().item()\n",
    "                best_vals[algo][-1].append(max_val)\n",
    "            else:\n",
    "                # randomly sample data\n",
    "                next_X= ini(q_eubo, dim=dim)\n",
    "                print(next_X)\n",
    "                # update data\n",
    "                X, comps = data[algo]\n",
    "                X, comps = make_new_data_u1(X, next_X, comps, q_comp_2)\n",
    "                data[algo] = (X, comps)\n",
    "    \n",
    "                # refit models\n",
    "                _, models[algo] = init_and_fit_model(X, comps)\n",
    "    \n",
    "                # record the best observed values so far\n",
    "                max_val = utility1(X).max().item()\n",
    "                best_vals[algo][-1].append(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_vals_case_1_evil.pkl', 'wb') as handle:\n",
    "    pickle.dump(best_vals, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_vals_case_1_evil.pkl', 'rb') as handle:\n",
    "    loaded_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "eRLF3-dFNzyW",
    "outputId": "9c83df50-e355-42b9-860e-b4b51d63f2c5"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "algo_labels = {\n",
    "    \"rand\": \"Random Exploration\",\n",
    "    \"EUBO-LLM\": \"EUBO-LLM\",\n",
    "    \"EUBO\": \"EUBO\", \n",
    "}\n",
    "\n",
    "\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(y.shape[0])\n",
    "\n",
    "\n",
    "# the utility function is maximized at the full vector of 1\n",
    "#optimal_val = utility(torch.tensor([[1] * dim])).item()\n",
    "iters = list(range(NUM_BATCHES + 1))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# plot the optimal value\n",
    "#ax.plot(\n",
    "#    iters,\n",
    "#    [optimal_val] * len(iters),\n",
    "#    label=\"Optimal Function Value\",\n",
    "#    color=\"black\",\n",
    "##    linewidth=1.5,\n",
    "#)\n",
    "\n",
    "# plot the the best observed value from each algorithm\n",
    "for algo in algos:\n",
    "    ys = np.vstack(best_vals[algo])\n",
    "    ax.errorbar(\n",
    "        iters, ys.mean(axis=0), yerr=ci(ys), label=algo_labels[algo], linewidth=1.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    #xlabel=f\"Number of queries q = {q_eubo}, num_initial_comp = {q_comp}, num_initial_samp = {q_data})\",\n",
    "    ylabel=\"Best observed value\\nas evaluated in the synthetic utility function\",\n",
    "    title=f\"Obj 1: minimising every output at the same time (typo in the word maximising)\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(np.arange(0, NUM_BATCHES + 1, 1))\n",
    "\n",
    "ax.set_xlabel(f\"Number of queries q = {q_eubo}, num_initial_comp = {q_comp}, num_initial_samp = {q_data})\", fontsize=10)  # Reducing the font size\n",
    "ax.legend(loc=\"best\")\n",
    "plt.savefig(\"comparison_first_case_1_evil_muejeje_corrected.png\",bbox_inches=\"tight\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47P-W6iDOiHp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:botorch_mar2024]",
   "language": "python",
   "name": "conda-env-botorch_mar2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
