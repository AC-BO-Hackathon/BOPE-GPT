{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NTeLbyDoMi0-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Suppress potential optimization warnings for cleaner notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DTLZ2_model\n",
    "import fischer_model\n",
    "from botorch.test_functions.multi_objective import DTLZ2\n",
    "from DTLZ2_model import neg_l1_dist\n",
    "from DTLZ2_model import predict_DTLZ2_model\n",
    "from fischer_model import predict_fischer_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6455, 0.0591, 0.1161, 0.5071]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fischer_model(torch.tensor([[0.5, 0.5, 0.5, 0.5]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('VEeUdMJ7GRqGNtuZfW0XdWP7JbSMoQiRuvZetNCL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mvj4PbSpNSjG"
   },
   "outputs": [],
   "source": [
    "# data generating helper functions\n",
    "#function that defines the comparisons\n",
    "def utility(X):\n",
    "    y=predict_fischer_model(X)\n",
    "    #weighted_y = y * torch.sqrt(torch.arange(y.size(-1), dtype=torch.float) + 1)\n",
    "    #y = torch.sum(weighted_y, dim=-1)\n",
    "    return y\n",
    "\n",
    "def utility1(X): #The four outputs are equally important, and we want to maximize all of them.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = torch.sum(y, dim=-1)\n",
    "    return y\n",
    "\n",
    "def utility2(X): #We only want to maximize the CO conversion.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = y[:,0]\n",
    "    return y\n",
    "\n",
    "def utility3(X): # The light oleffins is considered as a negative output and we want to minimize it while maximizing the other three objectives.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = y[:,0]+y[:,1]+y[:,2]-y[:,3]\n",
    "    return y\n",
    "\n",
    "\n",
    "def generate_data(n, dim=4):\n",
    "    \"\"\"Generate data X and y\"\"\"\n",
    "    # X is randomly sampled from dim-dimentional unit cube\n",
    "    # we recommend using double as opposed to float tensor here for\n",
    "    # better numerical stability\n",
    "    X = torch.rand(n, dim, dtype=torch.float64)\n",
    "    x_2=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    y = utility(x_2)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparisons(y, n_comp, noise=0.1, replace=False):\n",
    "    \"\"\"Create pairwise comparisons with noise\"\"\"\n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[\n",
    "        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n",
    "    ]\n",
    "    # add gaussian noise to the latent y values\n",
    "    c0 = y[comp_pairs[:, 0]] + np.random.standard_normal(len(comp_pairs)) * noise\n",
    "    c1 = y[comp_pairs[:, 1]] + np.random.standard_normal(len(comp_pairs)) * noise\n",
    "    reverse_comp = (c0 < c1).numpy()\n",
    "    comp_pairs[reverse_comp, :] = np.flip(comp_pairs[reverse_comp, :], 1)\n",
    "    comp_pairs = torch.tensor(comp_pairs).long()\n",
    "\n",
    "    return comp_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im not sure if this is is the correct function, i'm a bit eepy\n",
    "#remember to reduce the number of comparisons n_comp,\n",
    "def generate_comparisons_llm(y, n_comp, replace=False):\n",
    "    \"\"\"Create pairwise comparisons with noise\"\"\"\n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[\n",
    "        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n",
    "    ]\n",
    "    #parsing the tensor to get the strings for the LLM\n",
    "    new_pairs=[]\n",
    "    for opto in comp_pairs:\n",
    "        firstoption=opto[0]\n",
    "        secondoption=opto[1]\n",
    "        numfirst=(y[firstoption,:])\n",
    "        firstoutput1=f\"{numfirst[0].cpu().numpy():.1f}\"\n",
    "        firstoutput2=f\"{numfirst[1].cpu().numpy():.1f}\"\n",
    "        firstoutput3=f\"{numfirst[2].cpu().numpy():.1f}\"\n",
    "        firstoutput4=f\"{numfirst[3].cpu().numpy():.1f}\"\n",
    "        numsecond=(y[secondoption,:])\n",
    "        secondoutput1=f\"{numsecond[0].cpu().numpy():.1f}\"\n",
    "        secondoutput2=f\"{numsecond[1].cpu().numpy():.1f}\"\n",
    "        secondoutput3=f\"{numsecond[2].cpu().numpy():.1f}\"\n",
    "        secondoutput4=f\"{numsecond[3].cpu().numpy():.1f}\"\n",
    "        mess=\"Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane production, \"+firstoutput3+\" paraffins, \"+firstoutput4+\" light oleffins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane production, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "        print(mess)\n",
    "        response = co.chat(message=mess,\n",
    "        #perform web search before answering the question. You can also use your own custom connector.\n",
    "                          #connectors=[{\"id\": \"web-search\"}]\n",
    "        )\n",
    "        print(response.text)\n",
    "        opllm=response.text\n",
    "        \n",
    "        if \"Option A\" in opllm:\n",
    "            new_pairs.append(opto.tolist())\n",
    "        else:\n",
    "            new_pairs.append(list(reversed(opto)))\n",
    "        #api restrictions 20 API calls/minutes\n",
    "        time.sleep(6)\n",
    "    \n",
    "    return torch.tensor(new_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m5F2xn-8N-g9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "#parameters\n",
    "torch.manual_seed(123)\n",
    "#number for initial data\n",
    "n = 5 if not SMOKE_TEST else 5\n",
    "#number for initial comparisons\n",
    "m = 10 if not SMOKE_TEST else 10\n",
    "dim = 4\n",
    "noise = 0.1\n",
    "\n",
    "#generate data, initial data\n",
    "train_X, train_y = generate_data(n, dim=dim)\n",
    "#generating comparison based on the utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.8 light oleffins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.8 CO conversion, 0.3 methane production, 0.2 paraffins, 0.9 light oleffins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.1 paraffins, 0.8 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.8 light oleffins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.1 paraffins, 0.8 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light oleffins. Option B: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.1 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light oleffins. Option B: regime of 0.8 CO conversion, 0.3 methane production, 0.2 paraffins, 0.9 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.1 light oleffins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.1 paraffins, 0.8 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.8 light oleffins. Option B: regime of 0.8 CO conversion, 0.3 methane production, 0.2 paraffins, 0.9 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light oleffins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.1 paraffins, 0.8 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.8 light oleffins. Option B: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.1 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.8 CO conversion, 0.3 methane production, 0.2 paraffins, 0.9 light oleffins. Option B: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.1 light oleffins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n"
     ]
    }
   ],
   "source": [
    "train_comp_llm = generate_comparisons_llm(train_y, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 4],\n",
       "        [0, 4],\n",
       "        [1, 3],\n",
       "        [1, 2],\n",
       "        [4, 3],\n",
       "        [0, 2],\n",
       "        [1, 4],\n",
       "        [0, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comp_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fMuLBRO-NVj3"
   },
   "outputs": [],
   "source": [
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
    "from botorch.models.transforms.input import Normalize\n",
    "\n",
    "#fitting the first pairwise GP\n",
    "model = PairwiseGP(\n",
    "    train_X,\n",
    "    train_comp_llm,\n",
    "    input_transform=Normalize(d=train_X.shape[-1]),\n",
    ")\n",
    "mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n",
    "mll = fit_gpytorch_mll(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdxhkF6yNZKp",
    "outputId": "0e3b833e-7a46-4413-f148-7e3fab6d8433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Test Kendall-Tau rank correlation: 0.3778\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "\n",
    "# Kendall-Tau rank correlation\n",
    "def eval_kt_cor(model, test_X, test_y):\n",
    "    pred_y = model.posterior(test_X).mean.squeeze().detach().numpy()\n",
    "    return kendalltau(pred_y, test_y).correlation\n",
    "\n",
    "\n",
    "n_kendall = 10 if not SMOKE_TEST else 10\n",
    "\n",
    "test_X, test_y = generate_data(n_kendall, dim=dim)\n",
    "kt_correlation = eval_kt_cor(model, test_X, test_y[:,3])\n",
    "\n",
    "print(f\"Test Kendall-Tau rank correlation: {kt_correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7945, 0.1514, 0.1911, 0.7392],\n",
       "        [0.9282, 0.4849, 0.4895, 0.7640],\n",
       "        [0.7444, 0.0902, 0.1446, 0.7523],\n",
       "        [0.0901, 0.0080, 0.0231, 0.0540],\n",
       "        [0.7948, 0.1246, 0.2002, 0.5776],\n",
       "        [0.9339, 0.3518, 0.4522, 0.7336],\n",
       "        [0.2673, 0.0214, 0.0484, 0.1970],\n",
       "        [0.0938, 0.0056, 0.0161, 0.0463],\n",
       "        [0.9412, 0.4081, 0.5771, 0.7078],\n",
       "        [0.8666, 0.3808, 0.3012, 0.8189]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qEoN28RSNk2N"
   },
   "outputs": [],
   "source": [
    "from botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "#wrapper for the model\n",
    "def init_and_fit_model(X, comp):\n",
    "    \"\"\"Model fitting helper function\"\"\"\n",
    "    model = PairwiseGP(\n",
    "        X,\n",
    "        comp,\n",
    "        input_transform=Normalize(d=X.shape[-1]),\n",
    "    )\n",
    "    mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    return mll, model\n",
    "\n",
    "#wrapper for making new data, what does it mean? return comps\n",
    "\n",
    "def make_new_data(X, next_X, comps, q_comp):\n",
    "    \"\"\"Given X and next_X,\n",
    "    generate q_comp new comparisons between next_X\n",
    "    and return the concatenated X and comparisons\n",
    "    \"\"\"\n",
    "    # next_X is float by default; cast it to the dtype of X (i.e., double)\n",
    "    next_X = next_X.to(X)\n",
    "    x_2=tf.convert_to_tensor(next_X, dtype=tf.float32)\n",
    "    next_y = utility1(x_2)\n",
    "    next_comps = generate_comparisons_llm(next_y, n_comp=q_comp)\n",
    "    comps = torch.cat([comps, next_comps + X.shape[-2]])\n",
    "    X = torch.cat([X, next_X])\n",
    "    return X, comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1pTEh0DMNv1w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'comparisons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo \u001b[38;5;129;01min\u001b[39;00m algos:\n\u001b[1;32m     41\u001b[0m     best_vals[algo]\u001b[38;5;241m.\u001b[39mappend([])\n\u001b[0;32m---> 42\u001b[0m     data[algo] \u001b[38;5;241m=\u001b[39m (init_X, comparisons)\n\u001b[1;32m     43\u001b[0m     _, models[algo] \u001b[38;5;241m=\u001b[39m init_and_fit_model(init_X, comparisons)\n\u001b[1;32m     45\u001b[0m     best_next_y \u001b[38;5;241m=\u001b[39m utility1(init_X)\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comparisons' is not defined"
     ]
    }
   ],
   "source": [
    "#two algorithms to compare\n",
    "algos = [\"EUBO\",\"EUBO-LLM\", \"rand\"]\n",
    "#number of repetitions of the BO cycle\n",
    "NUM_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "#number of cycles\n",
    "NUM_BATCHES = 20 if not SMOKE_TEST else 2\n",
    "\n",
    "#dimension number= 4 inputs\n",
    "dim = 4\n",
    "#sampler options\n",
    "NUM_RESTARTS = 3\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 8\n",
    "#\n",
    "q_eubo = 2  # number of points per query\n",
    "q_data=5\n",
    "q_comp = 10  # number of comparisons per query\n",
    "q_comp_2=1\n",
    "\n",
    "# initial evals\n",
    "best_vals = {}  # best observed values\n",
    "for algo in algos:\n",
    "    best_vals[algo] = []\n",
    "\n",
    "# average over multiple trials\n",
    "for i in range(NUM_TRIALS):\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    data = {}\n",
    "    models = {}\n",
    "\n",
    "    # Create initial data\n",
    "    init_X, init_y = generate_data(q_data, dim=dim)\n",
    "    if algo == \"EUBO-LLM\":\n",
    "        comparisons = generate_comparisons_llm(init_y, q_comp)\n",
    "    if algo == \"EUBO\":\n",
    "        comparisons = generate_comparisons(init_y, q_comp)\n",
    "    # X are within the unit cube\n",
    "    bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "\n",
    "    for algo in algos:\n",
    "        best_vals[algo].append([])\n",
    "        data[algo] = (init_X, comparisons)\n",
    "        _, models[algo] = init_and_fit_model(init_X, comparisons)\n",
    "\n",
    "        best_next_y = utility1(init_X).max().item()\n",
    "        best_vals[algo][-1].append(best_next_y)\n",
    "\n",
    "    # we make additional NUM_BATCHES comparison queries after the initial observation\n",
    "    for j in range(1, NUM_BATCHES + 1):\n",
    "        print(j)\n",
    "        for algo in algos:\n",
    "            model = models[algo]\n",
    "            if algo == \"EUBO-LLM\" or algo == \"EUBO\":\n",
    "                # create the acquisition function object\n",
    "                acq_func = AnalyticExpectedUtilityOfBestOption(pref_model=model)\n",
    "                # optimize and get new observation\n",
    "                next_X, acq_val = optimize_acqf(\n",
    "                    acq_function=acq_func,\n",
    "                    bounds=bounds,\n",
    "                    q=q_eubo,\n",
    "                    num_restarts=NUM_RESTARTS,\n",
    "                    raw_samples=RAW_SAMPLES,\n",
    "                )\n",
    "            else:\n",
    "                # randomly sample data\n",
    "                next_X, _ = generate_data(q_eubo, dim=dim)\n",
    "            print(next_X)\n",
    "            # update data\n",
    "            X, comps = data[algo]\n",
    "            X, comps = make_new_data(X, next_X, comps, q_comp_2)\n",
    "            data[algo] = (X, comps)\n",
    "\n",
    "            # refit models\n",
    "            _, models[algo] = init_and_fit_model(X, comps)\n",
    "\n",
    "            # record the best observed values so far\n",
    "            max_val = utility(X).max().item()\n",
    "            best_vals[algo][-1].append(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "eRLF3-dFNzyW",
    "outputId": "9c83df50-e355-42b9-860e-b4b51d63f2c5"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'x' and 'y' must have the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo \u001b[38;5;129;01min\u001b[39;00m algos:\n\u001b[1;32m     35\u001b[0m     ys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(best_vals[algo])\n\u001b[0;32m---> 36\u001b[0m     ax\u001b[38;5;241m.\u001b[39merrorbar(\n\u001b[1;32m     37\u001b[0m         iters, ys\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), yerr\u001b[38;5;241m=\u001b[39mci(ys), label\u001b[38;5;241m=\u001b[39malgo_labels[algo], linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     40\u001b[0m ax\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m     41\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of queries (q = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_eubo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_comparisons = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq_comp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest observed value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj1: maximizing all the values\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m ax\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/botorch_mar2024/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/botorch_mar2024/lib/python3.11/site-packages/matplotlib/axes/_axes.py:3572\u001b[0m, in \u001b[0;36mAxes.errorbar\u001b[0;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[1;32m   3570\u001b[0m x, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(x, y)  \u001b[38;5;66;03m# Make sure all the args are iterable.\u001b[39;00m\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[0;32m-> 3572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must have the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3574\u001b[0m everymask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorevery_to_mask(x, errorevery)\n\u001b[1;32m   3576\u001b[0m label \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'x' and 'y' must have the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "algo_labels = {\n",
    "    \"rand\": \"Random Exploration\",\n",
    "    \"EUBO-LLM\": \"EUBO-LLM\",\n",
    "    \"EUBO\": \"EUBO\", \n",
    "}\n",
    "\n",
    "\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(y.shape[0])\n",
    "\n",
    "\n",
    "# the utility function is maximized at the full vector of 1\n",
    "#optimal_val = utility(torch.tensor([[1] * dim])).item()\n",
    "iters = list(range(NUM_BATCHES + 1))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# plot the optimal value\n",
    "#ax.plot(\n",
    "#    iters,\n",
    "#    [optimal_val] * len(iters),\n",
    "#    label=\"Optimal Function Value\",\n",
    "#    color=\"black\",\n",
    "##    linewidth=1.5,\n",
    "#)\n",
    "\n",
    "# plot the the best observed value from each algorithm\n",
    "for algo in algos:\n",
    "    ys = np.vstack(best_vals[algo])\n",
    "    ax.errorbar(\n",
    "        iters, ys.mean(axis=0), yerr=ci(ys), label=algo_labels[algo], linewidth=1.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    xlabel=f\"Number of queries (q = {q_eubo}, num_comparisons = {q_comp})\",\n",
    "    ylabel=\"Best observed value\",\n",
    "    title=f\"obj1: maximizing all the values\",\n",
    ")\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47P-W6iDOiHp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "botorch_mar2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
