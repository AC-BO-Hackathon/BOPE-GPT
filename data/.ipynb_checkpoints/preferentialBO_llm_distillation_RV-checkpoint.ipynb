{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change utility1 by the corresponding number, get back utility 3  done\n",
    "#change prompt done\n",
    "#change pickle filename  done\n",
    "#change plot name   done\n",
    "#change objective name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NTeLbyDoMi0-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Suppress potential optimization warnings for cleaner notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 07:50:27.184951: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-29 07:50:27.223956: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 07:50:27.953754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-29 07:50:28.392870: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-29 07:50:28.393531: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import DTLZ2_model\n",
    "import fischer_model\n",
    "from botorch.test_functions.multi_objective import DTLZ2\n",
    "from DTLZ2_model import neg_l1_dist\n",
    "from DTLZ2_model import predict_DTLZ2_model\n",
    "from fischer_model import predict_fischer_model\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll \n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood \n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Your chosen seed\n",
    "your_seed = 42\n",
    "\n",
    "# Set seed for Python's RNG\n",
    "random.seed(your_seed)\n",
    "\n",
    "# Set seed for NumPy RNG\n",
    "np.random.seed(your_seed)\n",
    "\n",
    "# Set seed for PyTorch RNGs\n",
    "torch.manual_seed(your_seed)\n",
    "\n",
    "# Ensure reproducibility for PyTorch operations (might reduce performance)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# If using CUDA (PyTorch)\n",
    "torch.cuda.manual_seed(your_seed)\n",
    "torch.cuda.manual_seed_all(your_seed)  # For multi-GPU setups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6455, 0.0591, 0.1161, 0.5071]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('9ylnov4iFULBLovujZIJLq6x8pkq4NkyNCw0oePR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Mvj4PbSpNSjG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Suppress potential optimization warnings for cleaner notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "import DTLZ2_model\n",
    "import fischer_model\n",
    "from botorch.test_functions.multi_objective import DTLZ2\n",
    "from DTLZ2_model import neg_l1_dist\n",
    "from DTLZ2_model import predict_DTLZ2_model\n",
    "from fischer_model import predict_fischer_model\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll \n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood \n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "import pickle\n",
    "\n",
    "#utils\n",
    "# data generating helper functions\n",
    "#function that defines the comparisons\n",
    "def utility(X):\n",
    "    y=predict_fischer_model(X)\n",
    "    #weighted_y = y * torch.sqrt(torch.arange(y.size(-1), dtype=torch.float) + 1)\n",
    "    #y = torch.sum(weighted_y, dim=-1)\n",
    "    return y\n",
    "\n",
    "def utility1(X): #The four outputs are equally important, and we want to maximize all of them.\n",
    "    y=predict_fischer_model(X)\n",
    "    y = torch.sum(y, dim=-1)\n",
    "    return y\n",
    "\n",
    "    \n",
    "def ini(n,dim):\n",
    "    X = torch.rand(n, dim, dtype=torch.float64)\n",
    "    return X\n",
    "\n",
    "def generate_data(X, dim=4):\n",
    "    \"\"\"Generate data X and y\"\"\"\n",
    "    # X is randomly sampled from dim-dimentional unit cube\n",
    "    # we recommend using double as opposed to float tensor here for\n",
    "    # better numerical stability\n",
    "    #X=ini(n,dim)\n",
    "    x_2=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    y = utility(x_2)\n",
    "    return y\n",
    "\n",
    "def generate_data_u1(X, dim=4):\n",
    "    \"\"\"Generate data X and y\"\"\"\n",
    "    # X is randomly sampled from dim-dimentional unit cube\n",
    "    # we recommend using double as opposed to float tensor here for\n",
    "    # better numerical stability\n",
    "    #X=ini(n,dim)\n",
    "    x_2=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    y = utility1(x_2)\n",
    "    return y\n",
    "def generate_comparisons(y, n_comp, noise=0.1, replace=False):\n",
    "    \"\"\"Create pairwise comparisons with noise\"\"\"\n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[\n",
    "        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n",
    "    ]\n",
    "    # add gaussian noise to the latent y values\n",
    "    c0 = y[comp_pairs[:, 0]] + np.random.standard_normal(len(comp_pairs)) * noise\n",
    "    c1 = y[comp_pairs[:, 1]] + np.random.standard_normal(len(comp_pairs)) * noise\n",
    "    reverse_comp = (c0 < c1).numpy()\n",
    "    comp_pairs[reverse_comp, :] = np.flip(comp_pairs[reverse_comp, :], 1)\n",
    "    comp_pairs = torch.tensor(comp_pairs).long()\n",
    "\n",
    "    return comp_pairs\n",
    "\n",
    "\n",
    "#wrapper for the model\n",
    "def init_and_fit_model(X, comp):\n",
    "    \"\"\"Model fitting helper function\"\"\"\n",
    "    model = PairwiseGP(\n",
    "        X,\n",
    "        comp,\n",
    "        input_transform=Normalize(d=X.shape[-1]),\n",
    "    )\n",
    "    mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    return mll, model\n",
    "\n",
    "\n",
    "\n",
    "def make_new_data(X, next_X, comps, q_comp):\n",
    "    \"\"\"Given X and next_X,\n",
    "    generate q_comp new comparisons between next_X\n",
    "    and return the concatenated X and comparisons\n",
    "    \"\"\"\n",
    "    # next_X is float by default; cast it to the dtype of X (i.e., double)\n",
    "    next_X = next_X.to(X)\n",
    "    x_2=tf.convert_to_tensor(next_X, dtype=tf.float32)\n",
    "    next_y = utility(x_2)\n",
    "    next_comps = generate_comparisons_llm(next_y, n_comp=q_comp)\n",
    "    comps = torch.cat([comps, next_comps + X.shape[-2]])\n",
    "    X = torch.cat([X, next_X])\n",
    "    return X, comps\n",
    "\n",
    "def make_new_data_u1(X, next_X, comps, q_comp):\n",
    "    \"\"\"Given X and next_X,\n",
    "    generate q_comp new comparisons between next_X\n",
    "    and return the concatenated X and comparisons\n",
    "    \"\"\"\n",
    "    # next_X is float by default; cast it to the dtype of X (i.e., double)\n",
    "    next_X = next_X.to(X)\n",
    "    x_2=tf.convert_to_tensor(next_X, dtype=tf.float32)\n",
    "    next_y = utility1(x_2)\n",
    "    next_comps = generate_comparisons(next_y, n_comp=q_comp)\n",
    "    comps = torch.cat([comps, next_comps + X.shape[-2]])\n",
    "    X = torch.cat([X, next_X])\n",
    "    return X, comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Suppress potential optimization warnings for cleaner notebook\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "import DTLZ2_model\n",
    "import fischer_model\n",
    "from botorch.test_functions.multi_objective import DTLZ2\n",
    "from DTLZ2_model import neg_l1_dist\n",
    "from DTLZ2_model import predict_DTLZ2_model\n",
    "from fischer_model import predict_fischer_model\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll \n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood \n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "co = cohere.Client('9ylnov4iFULBLovujZIJLq6x8pkq4NkyNCw0oePR')\n",
    "\n",
    "#remember to reduce the number of comparisons n_comp,\n",
    "# Add prompt input\n",
    "def generate_comparisons_llm(y, n_comp, replace=False):\n",
    "    \"\"\"Create pairwise comparisons with noise\"\"\"\n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[\n",
    "        np.random.choice(range(len(all_pairs)), n_comp, replace=replace)\n",
    "    ]\n",
    "    #parsing the tensor to get the strings for the LLM\n",
    "    new_pairs=[]\n",
    "    for opto in comp_pairs:\n",
    "        firstoption=opto[0]\n",
    "        secondoption=opto[1]\n",
    "        numfirst=(y[firstoption,:])\n",
    "        firstoutput1=f\"{numfirst[0].cpu().numpy():.1f}\"\n",
    "        firstoutput2=f\"{numfirst[1].cpu().numpy():.1f}\"\n",
    "        firstoutput3=f\"{numfirst[2].cpu().numpy():.1f}\"\n",
    "        firstoutput4=f\"{numfirst[3].cpu().numpy():.1f}\"\n",
    "        numsecond=(y[secondoption,:])\n",
    "        secondoutput1=f\"{numsecond[0].cpu().numpy():.1f}\"\n",
    "        secondoutput2=f\"{numsecond[1].cpu().numpy():.1f}\"\n",
    "        secondoutput3=f\"{numsecond[2].cpu().numpy():.1f}\"\n",
    "        secondoutput4=f\"{numsecond[3].cpu().numpy():.1f}\"\n",
    "        mess=\"Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane production, \"+firstoutput3+\" paraffins, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane production, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "        print(mess)\n",
    "        response = co.chat(message=mess,\n",
    "        #perform web search before answering the question. You can also use your own custom connector.\n",
    "                          #connectors=[{\"id\": \"web-search\"}]\n",
    "        )\n",
    "        print(response.text)\n",
    "        opllm=response.text\n",
    "        \n",
    "        if \"Option A\" in opllm:\n",
    "            new_pairs.append(opto.tolist())\n",
    "        else:\n",
    "            new_pairs.append(list(reversed(opto)))\n",
    "        #api restrictions 20 API calls/minutes\n",
    "        time.sleep(6)\n",
    "    \n",
    "    return torch.tensor(new_pairs)\n",
    "\n",
    "#\"Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane production, \"+firstoutput3+\" paraffins, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane production, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "#\"Suppose you're managing a Fischer-Tropsch synthesis process. The light olefins are considered as a negative output and we want to minimize them, while maximizing the other three outputs. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane, \"+firstoutput3+\" paraffin, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\"\n",
    "#\"Suppose you're managing a Fischer-Tropsch synthesis process. We only want to maximize the CO conversion. Option A: regime of \"+firstoutput1+\" CO conversion, \"+firstoutput2+\" methane, \"+firstoutput3+\" paraffin, \"+firstoutput4+\" light olefins. Option B: regime of \"+secondoutput1+\" CO conversion, \"+secondoutput2+\" methane, \"+secondoutput3+\" paraffins, \"+secondoutput4+\" light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qEoN28RSNk2N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1pTEh0DMNv1w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Option B: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.5 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.7 CO conversion, 0.1 methane production, 0.2 paraffins, 0.4 light olefins. Option B: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Option B: regime of 0.5 CO conversion, 0.0 methane production, 0.1 paraffins, 0.6 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.7 CO conversion, 0.1 methane production, 0.2 paraffins, 0.4 light olefins. Option B: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.5 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.7 CO conversion, 0.1 methane production, 0.2 paraffins, 0.4 light olefins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option A.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.2 CO conversion, 0.0 methane production, 0.0 paraffins, 0.2 light olefins. Option B: regime of 0.8 CO conversion, 0.1 methane production, 0.2 paraffins, 0.6 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n",
      "Option B.\n",
      "Suppose you're managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of 0.5 CO conversion, 0.0 methane production, 0.1 paraffins, 0.6 light olefins. Option B: regime of 0.6 CO conversion, 0.0 methane production, 0.1 paraffins, 0.5 light olefins. Choose only one option, only answer with 'Option A' or 'Option B'\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "The read operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_backends/sync.py:124\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    123\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 124\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEUBO-LLM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     38\u001b[0m     init_y \u001b[38;5;241m=\u001b[39m generate_data(init_X, dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[0;32m---> 39\u001b[0m     comparisons \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_comparisons_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_comp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algo \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEUBO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     41\u001b[0m     init_y \u001b[38;5;241m=\u001b[39m generate_data_u1(init_X, dim\u001b[38;5;241m=\u001b[39mdim)\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mgenerate_comparisons_llm\u001b[0;34m(y, n_comp, replace)\u001b[0m\n\u001b[1;32m     26\u001b[0m mess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuppose you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre managing a Fischer-Tropsch synthesis process. The four outputs are equally important, and we want to maximize all of them. Option A: regime of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfirstoutput1\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m CO conversion, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfirstoutput2\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m methane production, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfirstoutput3\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m paraffins, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mfirstoutput4\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m light olefins. Option B: regime of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msecondoutput1\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m CO conversion, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msecondoutput2\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m methane production, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msecondoutput3\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m paraffins, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msecondoutput4\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m light olefins. Choose only one option, only answer with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOption A\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOption B\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(mess)\n\u001b[0;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;66;43;03m#perform web search before answering the question. You can also use your own custom connector.\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m#connectors=[{\"id\": \"web-search\"}]\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     33\u001b[0m opllm\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/cohere/client.py:27\u001b[0m, in \u001b[0;36mvalidate_args.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m     26\u001b[0m     check_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/cohere/base_client.py:626\u001b[0m, in \u001b[0;36mBaseCohere.chat\u001b[0;34m(self, message, model, preamble, chat_history, conversation_id, prompt_truncation, connectors, search_queries_only, documents, temperature, max_tokens, k, p, seed, stop_sequences, frequency_penalty, presence_penalty, raw_prompting, tools, tool_results, request_options)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OMIT:\n\u001b[1;32m    625\u001b[0m     _request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_results\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tool_results\n\u001b[0;32m--> 626\u001b[0m _response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murljoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_query_parameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_body_parameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_body_parameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjsonable_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_none_from_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_headers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout_in_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout_in_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_retries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pydantic\u001b[38;5;241m.\u001b[39mparse_obj_as(NonStreamedChatResponse, _response\u001b[38;5;241m.\u001b[39mjson())  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/cohere/core/http_client.py:94\u001b[0m, in \u001b[0;36mHttpClient.request\u001b[0;34m(self, max_retries, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(httpx\u001b[38;5;241m.\u001b[39mClient\u001b[38;5;241m.\u001b[39mrequest)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, max_retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, retries: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny\n\u001b[1;32m     93\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m---> 94\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _should_retry(response\u001b[38;5;241m=\u001b[39mresponse):\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_retries \u001b[38;5;241m>\u001b[39m retries:\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    826\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_transports/default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    153\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/envs/botorch_mar2024/lib/python3.11/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out"
     ]
    }
   ],
   "source": [
    "#two algorithms to compare\n",
    "algos = [\"EUBO\",\"EUBO-LLM\", \"rand\"]\n",
    "#number of repetitions of the BO cycle\n",
    "NUM_TRIALS = 3 if not SMOKE_TEST else 2\n",
    "#number of cycles\n",
    "NUM_BATCHES = 20 if not SMOKE_TEST else 2\n",
    "\n",
    "#dimension number= 4 inputs\n",
    "dim = 4\n",
    "#sampler options\n",
    "NUM_RESTARTS = 3\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 8\n",
    "#\n",
    "q_eubo = 2  # number of points per query\n",
    "q_data=5\n",
    "q_comp = 10  # number of comparisons per query\n",
    "q_comp_2=1\n",
    "\n",
    "# initial evals\n",
    "best_vals = {}  # best observed values\n",
    "for algo in algos:\n",
    "    best_vals[algo] = []\n",
    "\n",
    "# average over multiple trials\n",
    "for i in range(NUM_TRIALS):\n",
    "    torch.manual_seed(i)\n",
    "    np.random.seed(i)\n",
    "    data = {}\n",
    "    models = {}\n",
    "\n",
    "     # X are within the unit cube\n",
    "    bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "\n",
    "    # Create initial data\n",
    "    init_X=ini(q_data,dim)\n",
    "    if algo == \"EUBO-LLM\":\n",
    "        init_y = generate_data(init_X, dim=dim)\n",
    "        comparisons = generate_comparisons_llm(init_y, q_comp)\n",
    "    if algo == \"EUBO\":\n",
    "        init_y = generate_data_u1(init_X, dim=dim)\n",
    "        comparisons = generate_comparisons(init_y, q_comp)\n",
    "    if algo == \"rand\":\n",
    "        init_y = generate_data_u1(init_X, dim=dim)\n",
    "        comparisons = generate_comparisons(init_y, q_comp)\n",
    "   \n",
    "    best_vals[algo].append([])\n",
    "    data[algo] = (init_X, comparisons)\n",
    "     _, models[algo] = init_and_fit_model(init_X, comparisons)\n",
    "\n",
    "    best_next_y = utility1(init_X).max().item()\n",
    "    best_vals[algo][-1].append(best_next_y)\n",
    "\n",
    "\n",
    "    model = models[algo]\n",
    "    if algo == \"EUBO-LLM\":\n",
    "        # create the acquisition function objec\n",
    "        acq_func = AnalyticExpectedUtilityOfBestOption(pref_model=model)\n",
    "        # optimize and get new observation\n",
    "        next_X, acq_val = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=q_eubo,\n",
    "                num_restarts=NUM_RESTARTS,\n",
    "                raw_samples=RAW_SAMPLES,\n",
    "        )\n",
    "         \n",
    "        # update data\n",
    "        X, comps = data[algo]\n",
    "        X, comps = make_new_data(X, next_X, comps, q_comp_2)\n",
    "        data[algo] = (X, comps)\n",
    "    \n",
    "        # refit models\n",
    "        _, models[algo] = init_and_fit_model(X, comps)\n",
    "    \n",
    "        # record the best observed values so far\n",
    "        max_val = utility1(X).max().item()\n",
    "        best_vals[algo][-1].append(max_val)\n",
    "    elif algo == \"EUBO\":\n",
    "        #create the acquisition function object\n",
    "        acq_func = AnalyticExpectedUtilityOfBestOption(pref_model=model)\n",
    "        # optimize and get new observation\n",
    "        next_X, acq_val = optimize_acqf(\n",
    "                    acq_function=acq_func,\n",
    "                    bounds=bounds,\n",
    "                    q=q_eubo,\n",
    "                    num_restarts=NUM_RESTARTS,\n",
    "                    raw_samples=RAW_SAMPLES,\n",
    "                )\n",
    "        print(next_X)\n",
    "            # update data\n",
    "        X, comps = data[algo]\n",
    "        X, comps = make_new_data_u1(X, next_X, comps, q_comp_2)\n",
    "        data[algo] = (X, comps)\n",
    "    \n",
    "                # refit models\n",
    "        _, models[algo] = init_and_fit_model(X, comps)\n",
    "    \n",
    "                # record the best observed values so far\n",
    "        max_val = utility1(X).max().item()\n",
    "        best_vals[algo][-1].append(max_val)\n",
    "    else:\n",
    "            # randomly sample data\n",
    "        next_X= ini(q_eubo, dim=dim)\n",
    "        print(next_X)\n",
    "        # update data\n",
    "        X, comps = data[algo]\n",
    "        X, comps = make_new_data_u1(X, next_X, comps, q_comp_2)\n",
    "        data[algo] = (X, comps)\n",
    "    \n",
    "        # refit models\n",
    "        _, models[algo] = init_and_fit_model(X, comps)\n",
    "    \n",
    "        # record the best observed values so far\n",
    "        max_val = utility1(X).max().item()\n",
    "        best_vals[algo][-1].append(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_vals_case_1.pkl', 'wb') as handle:\n",
    "    pickle.dump(best_vals, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_vals_case_1.pkl', 'rb') as handle:\n",
    "    loaded_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "eRLF3-dFNzyW",
    "outputId": "9c83df50-e355-42b9-860e-b4b51d63f2c5"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "algo_labels = {\n",
    "    \"rand\": \"Random Exploration\",\n",
    "    \"EUBO-LLM\": \"EUBO-LLM\",\n",
    "    \"EUBO\": \"EUBO\", \n",
    "}\n",
    "\n",
    "\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(y.shape[0])\n",
    "\n",
    "\n",
    "# the utility function is maximized at the full vector of 1\n",
    "#optimal_val = utility(torch.tensor([[1] * dim])).item()\n",
    "iters = list(range(NUM_BATCHES + 1))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# plot the optimal value\n",
    "#ax.plot(\n",
    "#    iters,\n",
    "#    [optimal_val] * len(iters),\n",
    "#    label=\"Optimal Function Value\",\n",
    "#    color=\"black\",\n",
    "##    linewidth=1.5,\n",
    "#)\n",
    "\n",
    "# plot the the best observed value from each algorithm\n",
    "for algo in algos:\n",
    "    ys = np.vstack(best_vals[algo])\n",
    "    ax.errorbar(\n",
    "        iters, ys.mean(axis=0), yerr=ci(ys), label=algo_labels[algo], linewidth=1.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    #xlabel=f\"Number of queries q = {q_eubo}, num_initial_comp = {q_comp}, num_initial_samp = {q_data})\",\n",
    "    ylabel=\"Best observed value\\nas evaluated in the synthetic utility function\",\n",
    "    title=f\"Obj 1: maximising every output at the same time, with the same importance\",\n",
    ")\n",
    "\n",
    "ax.set_xticks(np.arange(0, NUM_BATCHES + 1, 1))\n",
    "\n",
    "ax.set_xlabel(f\"Number of queries q = {q_eubo}, num_initial_comp = {q_comp}, num_initial_samp = {q_data})\", fontsize=10)  # Reducing the font size\n",
    "ax.legend(loc=\"best\")\n",
    "plt.savefig(\"comparison_first_case_1_corrected.png\",bbox_inches=\"tight\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47P-W6iDOiHp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:botorch_mar2024]",
   "language": "python",
   "name": "conda-env-botorch_mar2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
