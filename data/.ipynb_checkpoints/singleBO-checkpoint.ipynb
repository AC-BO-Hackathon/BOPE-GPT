{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import qExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from torch.quasirandom import SobolEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_fischer_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_floatx('float32')\n",
    "import json\n",
    "\n",
    "\n",
    "# ANN structure\n",
    "N_neurons=20\n",
    "N_layers=1\n",
    "\n",
    "model = Sequential()\n",
    "if N_layers==1:\n",
    "     model.add(Dense(N_neurons, activation = 'sigmoid', input_dim = 4))\n",
    "elif N_layers==2 :\n",
    "    model.add(Dense(N_neurons, activation = 'sigmoid', input_dim = 4))\n",
    "    model.add(Dense(units = N_neurons, activation = 'relu'))\n",
    "elif N_layers==3 :\n",
    "    model.add(Dense(N_neurons, activation = 'sigmoid', input_dim = 4))\n",
    "    model.add(Dense(units = N_neurons, activation = 'relu'))\n",
    "    model.add(Dense(units = N_neurons, activation = 'relu'))\n",
    "else:\n",
    "    print(\"Check no of layers\")\n",
    "model.add(Dense(units = 4))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "# Load the model\n",
    "with open('fischer_ann_weights.json', 'r') as f:\n",
    "    weights_list = json.load(f)\n",
    "\n",
    "weights = [np.array(w) for w in weights_list]\n",
    "model.set_weights(weights)\n",
    "\n",
    "# Test the model\n",
    "df = pd.read_csv(\"fischer_data_processed.csv\",sep=\",\")\n",
    "X = df.iloc[:,0:4].astype('float32')\n",
    "y = df.iloc[:,4:8].astype('float32')\n",
    "\n",
    "\n",
    "def predict_fischer_model(X, negate=False):\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred=torch.Tensor(y_pred)\n",
    "\n",
    "    if negate:\n",
    "        return -y_pred\n",
    "    else:\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dtype = torch.float32\n",
    "bounds = torch.tensor([[0., 0., 0., 0.], [1., 1., 1., 1.]], dtype=dtype, device=device)\n",
    "\n",
    "N = 7\n",
    "batch_size=5\n",
    "iteration_number=20\n",
    "\n",
    "iterations = list(range(1, iteration_number+1))\n",
    "supra_best=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobol sampling\n",
    "sobol_engine = SobolEngine(dimension=4, scramble=False)  # 4 dimensions for your input space\n",
    "train_x = draw_sobol_samples(bounds=bounds, n=1, q=N).squeeze(0).cpu()\n",
    "x_2=tf.convert_to_tensor(train_x, dtype=tf.float32)\n",
    "train_y = predict_fischer_model(x_2, negate=True)[:, 1].unsqueeze(-1)\n",
    "\n",
    "models = []\n",
    "\n",
    "gp_model = SingleTaskGP(train_x, train_y).to(device=device, dtype=dtype)\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "models.append(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquisition function\n",
    "frames_x = [train_x.cpu().numpy()]\n",
    "frames_y = [train_y.cpu().numpy()]\n",
    "best_points = []\n",
    "best_y_values=[]\n",
    "\n",
    "for iteration in range(iteration_number):\n",
    "    EI = qExpectedImprovement(model=gp_model, best_f=train_y.max())#, maximize=True)\n",
    "    #optimisation of acquisition function\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function=EI,\n",
    "        bounds=bounds,\n",
    "        q=batch_size,\n",
    "        num_restarts=5,\n",
    "        raw_samples=20,\n",
    "        options={\"dtype\": dtype, \"device\": device}\n",
    "    )\n",
    "    candidate_2=tf.convert_to_tensor(candidate.cpu().numpy(), dtype=tf.float32)\n",
    "    new_y = predict_fischer_model(candidate_2, negate=True)[:, 0].unsqueeze(-1)\n",
    "    train_x = torch.cat([train_x, candidate])\n",
    "    train_y = torch.cat([train_y, new_y])\n",
    "\n",
    "    gp_model = SingleTaskGP(train_x, train_y).to(device=device, dtype=dtype)\n",
    "    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "    fit_gpytorch_model(mll)\n",
    "\n",
    "    frames_x.append(train_x.cpu().numpy())\n",
    "    frames_y.append(train_y.cpu().numpy())\n",
    "    best_points.append(train_x[train_y.argmax(), :].cpu().numpy())\n",
    "    best_y_values.append(train_y.max().cpu().numpy())\n",
    "    models.append(gp_model)\n",
    "\n",
    "best_point = train_x[train_y.argmax(), :]\n",
    "best_value = train_y.max().item()\n",
    "\n",
    "best_y_values = np.array([element for element in best_y_values])\n",
    "supra_best.append(best_y_values)\n",
    "\n",
    "print(\"Best observed point:\", best_point.cpu().numpy(), \"Best observed value:\", best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp_mean(model, bounds, resolution=100):\n",
    "    x1 = torch.linspace(bounds[0, 0], bounds[1, 0], resolution, dtype=dtype, device=device)\n",
    "    x2 = torch.linspace(bounds[0, 1], bounds[1, 1], resolution, dtype=dtype, device=device)\n",
    "    X1, X2 = torch.meshgrid(x1, x2)\n",
    "    grid = torch.stack([X1.flatten(), X2.flatten()], -1)\n",
    "    with torch.no_grad():\n",
    "        mean = model.posterior(grid).mean.cpu().numpy().reshape(resolution, resolution)\n",
    "    return X1.cpu().numpy(), X2.cpu().numpy(), mean\n",
    "\n",
    "def update(frame):\n",
    "    plt.clf()\n",
    "    X1, X2, mean = plot_gp_mean(models[frame], bounds)\n",
    "    cp = plt.contourf(X1, X2, mean, levels=50, cmap=cm.viridis)\n",
    "    plt.colorbar(cp)\n",
    "    plt.scatter(frames_x[frame][:, 0], frames_x[frame][:, 1], color=\"red\")\n",
    "    plt.title(f\"Iteration {frame+1}\")\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the best Y values vs iterations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, best_y_values, marker='o', linestyle='-', color='b')\n",
    "plt.title('Best Y Values vs Iterations', fontsize = 20)\n",
    "plt.xlabel('Iteration', fontsize = 20)\n",
    "plt.ylabel('Best Y Value', fontsize = 20)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botorch_mar2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
